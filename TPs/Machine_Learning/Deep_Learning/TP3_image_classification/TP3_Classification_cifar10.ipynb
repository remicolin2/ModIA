{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "792345b7-cf19-45fd-936b-fa281f800c3d",
   "metadata": {},
   "source": [
    "# Multiclass classification: The [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset\n",
    "\n",
    "In this tutorial, we will implement a simple convolutional network based on the VGG-16 architecture, which we will apply to multiclass image classification. We will use the CIFAR-10 dataset, a standard for this type of (elementary) problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9a374-f0f7-4757-850a-4a6f8a2d9c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa5a8d-6191-439d-a267-de17d0280e54",
   "metadata": {},
   "source": [
    "## Load the CIFAR-10 Dataset\n",
    "\n",
    "The CIFAR-10 dataset consists of 60,000 color images from 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. Several sample images are shown below, along with the class names.\n",
    "\n",
    "<center><img src=\"https://production-media.paperswithcode.com/datasets/4fdf2b82-2bc3-4f97-ba51-400322b228b1.png\"\n",
    "             style=\"width:500px;\"></center>\n",
    "<caption><center><b> Figure 1: Some images of the database</b></center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc00c5-59f0-4229-994e-845bcd05fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8aa0f0-04f2-4e25-bb44-22ac542a3842",
   "metadata": {},
   "source": [
    "Since the CIFAR-10 dataset is included in _TensorFlow_, we can load the dataset using the _load_data()_ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac045b-6465-4610-966a-85a64a7aca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    " \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d489ad-2c4e-4067-8ed2-89f8fc9d0cbf",
   "metadata": {},
   "source": [
    "##### <i style=\"color:purple\">**Exercise**: Display sample images from the dataset.</i>\n",
    "\n",
    "It is always a good idea to inspect some images in a dataset. Display a sample image, with its associated label as a title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4948729-4812-4fad-a091-98781dfea34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining array. Each item of array represent integer value of labels. 10 items for 10 labels.\n",
    "\n",
    "class_names =['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610d1944-3dd4-4c70-8173-15bc049cb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/cifar10/data_visualization.py\n",
    "plt.figure(figsize=(18, 9))\n",
    " \n",
    "n_rows = 4\n",
    "n_cols = 8\n",
    " \n",
    "# plot each of the images in the batch and the associated ground truth labels\n",
    "for i in range(n_rows*n_cols):\n",
    "    ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "    plt.imshow(X_train[i,:,:])\n",
    "    title = '['+y_train[i][0].astype('str')+'] '+class_names[y_train[i][0]]\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a989dff4-0b0a-431c-be1b-5d265de902a4",
   "metadata": {},
   "source": [
    "Remember, the images in CIFAR-10 are quite small, only 32×32 pixels, so while they do not have much detail, there is still enough information in these images to support an image classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9600864a-5e60-4588-ba2e-194b8bde18f1",
   "metadata": {},
   "source": [
    "##### <i style=\"color:purple\">**Exercise**: Preprocess the data.</i>\n",
    "\n",
    "* Normalize the image data to the range $[0,1]$.\n",
    "* Convert the integer labels to one-hot encoded labels. Pour ce faire, on pourra utiliser la fonction [_to_categorical()_](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b11869-c853-4e03-ae7e-6431c9d171be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06ed4ed-e382-4cf0-a932-002c2611c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/cifar10/data_preprocessing.py\n",
    "# Normalize images to the range [0, 1].\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test  = X_test.astype(\"float32\") / 255\n",
    " \n",
    "# Change the labels from integer to categorical data.\n",
    "print('Original (integer) label for the first training sample: ', y_train[0])\n",
    " \n",
    "# Convert labels to one-hot encoding.\n",
    "y_train = to_categorical(y_train)\n",
    "y_test  = to_categorical(y_test)\n",
    " \n",
    "print('After conversion to categorical one-hot encoded labels: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63ca9e-0dd8-4784-9ced-41c84b7eee92",
   "metadata": {},
   "source": [
    "## CNN Model Implementation\n",
    "\n",
    "This section will define a simple CNN model in Keras and train it on the CIRFAR-10 dataset.\n",
    "\n",
    "The simple model we propose is shown in Figure 2. Its structure is similar to that of the VGG-16. However, it has fewer layers, and the size of the input images is much smaller, considerably reducing the number of trainable parameters. More specifically, this model contains three convolutional blocks and a fully connected layer - our classifier. \n",
    "The figure shows the number of filters at the end of each convolutional block, as well as the size of the convolution output images. \n",
    "\n",
    "To be more precise:\n",
    "* The first convolutional block is composed of two convolutional layers with 32 filters each, followed by a max pooling layer with a stride of 2 so that the output shape from this first convolutional block is (16×16 x32). \n",
    "* The second convolutional block is nearly identical to the first but with 64 filters in each convolutional layer instead of 32. \n",
    "* Finally, the third convolutional block is an exact copy of the second one.\n",
    "\n",
    "<center><img src=\"https://learnopencv.com/wp-content/uploads/2023/01/tensorflow-keras-cnn-architecture.png\"\n",
    "             style=\"width:800px;\"></center>\n",
    "<caption><center><b> Figure 2: CNN architecture</b></center></caption>\n",
    "<br>\n",
    "\n",
    "_**Note:** The number of filters in each convolutional layer is something that you will need to experiment with. A larger number of filters allows the model to have a greater learning capacity, but this also needs to be balanced with the amount of data available to train the model. Adding too many filters (or layers) can lead to overfitting, one of the most common issues encountered when training models._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fedf0d-4afa-4d2d-a376-a6763dc7039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9129a9-24a8-4557-891a-42a9589f016a",
   "metadata": {},
   "source": [
    "##### <i style=\"color:purple\">**Exercise**: Define the CNN architecture.</i>\n",
    "\n",
    "Define a _cnn_model()_ function that instantiates the network described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b76f8d-412c-410a-a2d6-1f5658f45217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/cifar10/cnn_model.py\n",
    "def cnn_model(input_shape=(32, 32, 3)):\n",
    "     \n",
    "    model = Sequential()\n",
    "     \n",
    "    #------------------------------------\n",
    "    # Conv Block 1: 32 Filters, MaxPool.\n",
    "    #------------------------------------\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "    #------------------------------------\n",
    "    # Conv Block 2: 64 Filters, MaxPool.\n",
    "    #------------------------------------\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "    #------------------------------------\n",
    "    # Conv Block 3: 64 Filters, MaxPool.\n",
    "    #------------------------------------\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "     \n",
    "    #------------------------------------\n",
    "    # Flatten the convolutional features.\n",
    "    #------------------------------------\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c13bea-bd6f-41f2-ab09-e6b54bb3a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96cb7cf-eb64-4560-af35-f91248cc667d",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "For training, you can use the following hyperparameters :\n",
    "* `batch_size` = 256\n",
    "* `epochs` = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1106b87-e777-4670-8dcd-b9fe383fbed9",
   "metadata": {},
   "source": [
    "##### <i style=\"color:purple\">**Exercise**: Compile and train the model.</i>\n",
    "\n",
    "You will use the _rmsprop_ optimizer, and track _accuracy_. For training, you can use the _validation_split_ agument to reserve 30% of the dataset for model validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca98f7c-ac56-4f8b-b3e3-4c44f21d9397",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load solutions/cifar10/cnn_train.py\n",
    "batch_size = 256\n",
    "epochs = 30\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', \n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'],\n",
    "             )\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs, \n",
    "                    verbose = 1, \n",
    "                    validation_split = .3,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0770d609-ba5e-484d-a473-80476603fcf6",
   "metadata": {},
   "source": [
    "_**Note**: The _validation_split_ argument reserves the last % of the training dataset for validation. This approach is very convenient, but if the training data set has a specific order (for example, order by classes), you must take steps to randomize the order before proceeding with the split._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b5556-b9fc-4f23-87f7-593842fc4c12",
   "metadata": {},
   "source": [
    "##### <i style=\"color:purple\">**Exercise** : Visualize the evolution of metrics during training.</i>\n",
    "\n",
    "You will write a function displaying the evolution of metrics during training, on the training and validation sets. Display accuracy and loss on separate figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9dc5394-e758-499a-9e98-5d28e26a849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/cifar10/plot_training_analysis.py\n",
    "def plot_training_analysis():\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, acc, 'b', linestyle=\"--\",label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'g', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, loss, 'b', linestyle=\"--\",label='Training loss')\n",
    "    plt.plot(epochs, val_loss,'g', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd698a8c-93d0-4ab9-9b73-d5ec7c74e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eb6616-3dc3-4347-9bd2-5a77581eb238",
   "metadata": {},
   "source": [
    "The results from our baseline model reveal that the model is **overfitting**. Notice that the validation loss increases after about ten epochs of training while the training loss continues to decline. This means the network learns to model the training data well but does not generalize to unseen test data. The accuracy plot shows a similar trend where the validation accuracy levels off after about ten epochs while the training accuracy approaches 100% as training progresses. \n",
    "\n",
    "This is a common problem when training neural networks and can occur for several reasons. One reason is that the model can fit the nuances of the training dataset, especially when the training dataset is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc77463-da79-4c6c-8ac6-21e3f8876c93",
   "metadata": {},
   "source": [
    "## Adding dropout to the model\n",
    "\n",
    "To help mitigate this problem, we can employ one or more regularization strategies to help the model generalize better. Regularization techniques help to restrict the model’s flexibility so that it does not overfit the training data.\n",
    "Dropout is implemented in Keras as a particular layer type that randomly drops a percentage of neurons during training. When dropout is used in convolutional layers, usually after the max pooling layer, it eliminates a percentage of neurons in the feature maps. When used after a dense layer, a percentage of neurons in the fully connected layer are dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d770018-f62c-4005-8e24-9e2dd79d9499",
   "metadata": {},
   "source": [
    "##### <i style=\"color:purple\">**Exercise** : Add dropout to previous CNN.</i>\n",
    "\n",
    "Add a dropout layer at the end of each convolutional block and also after the first dense layer in the classifier. The input argument to the Dropout function is the fraction of neurons to (randomly) drop from the previous layer during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c01604-48f1-4416-8d0c-8855855d766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2c0dba-3d2f-4d12-b455-4f1e4b98e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/cifar10/cnn_model_dropout.py\n",
    "def cnn_model_dropout(input_shape=(32, 32, 3)):\n",
    "     \n",
    "    model = Sequential()\n",
    "     \n",
    "    #------------------------------------\n",
    "    # Conv Block 1: 32 Filters, MaxPool.\n",
    "    #------------------------------------\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    #------------------------------------\n",
    "    # Conv Block 2: 64 Filters, MaxPool.\n",
    "    #------------------------------------\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    #------------------------------------\n",
    "    # Conv Block 3: 64 Filters, MaxPool.\n",
    "    #------------------------------------\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "     \n",
    "    #------------------------------------\n",
    "    # Flatten the convolutional features.\n",
    "    #------------------------------------\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98e635-ee49-4795-9cff-59329647e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model_dropout()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ecfaae-a0f7-4366-acd8-b76df5f4ed4c",
   "metadata": {},
   "source": [
    "##### <i style=\"color:purple\">**Exercise**: Compile and train the model.</i>\n",
    "\n",
    "Use the same parameters as previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c718e519-d991-4cf5-9469-124cf2f4e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/cifar10/cnn_train.py\n",
    "batch_size = 256\n",
    "epochs = 30\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', \n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'],\n",
    "             )\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs, \n",
    "                    verbose = 1, \n",
    "                    validation_split = .3,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986fa6a-9133-4d15-bce2-0a30fb00f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc8030-6b9f-41a9-9893-53c11439dd7c",
   "metadata": {},
   "source": [
    "In the graphs above, the training curves align very closely with the validation curves. Note also that we achieve higher validation accuracy than the baseline model, which contained no dropouts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a1746-87ce-469f-94ca-ffdff7099756",
   "metadata": {},
   "source": [
    "## Evaluate the model on the test dataset\n",
    "\n",
    "We can now predict the results for all the test images, as shown in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0209ec2-c79f-4777-8bfe-90dafe0fdc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc*100:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c770b3d-ec2f-4e3a-8785-3eabfa9a5ba6",
   "metadata": {},
   "source": [
    "##### <i style=\"color:purple\">**Exercise**: Evaluate the model.</i>\n",
    "\n",
    "Write an _evaluate_model()_ function that, given a dataset and a model:\n",
    "* Selects a batch of data,\n",
    "* Determines the labels predicted by the model for this data,\n",
    "* Displays the selected images, comparing the true and predicted labels as titles. The titles will be colored green when the two labels coincide and red when they do not. <br>\n",
    "The [_plt.setp_](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.setp.html) function is used to change the style of an object via the `plt.setp(obj, style)` synthaxis.\n",
    "* Counts the number of correctly predicted labels and displays the percentage of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e23ca59-ecbf-43c4-911d-592237d823e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/cifar10/evaluate_model.py\n",
    "def evaluate_model(dataset, model):\n",
    " \n",
    "    class_names =['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "    n_rows = 3\n",
    "    n_cols = 6\n",
    "     \n",
    "    # Retrieve a number of images from the dataset.\n",
    "    data_batch = dataset[0:n_rows*n_cols]\n",
    " \n",
    "    # Get predictions from model.  \n",
    "    predictions = model.predict(data_batch)\n",
    " \n",
    "    plt.figure(figsize=(20, 8))\n",
    "    n_matches = 0\n",
    "         \n",
    "    for idx in range(n_rows*n_cols):\n",
    "        ax = plt.subplot(n_rows, n_cols, idx+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(data_batch[idx])\n",
    " \n",
    "        pred_idx = tf.argmax(predictions[idx]).numpy()\n",
    "        truth_idx = np.nonzero(y_test[idx])\n",
    "             \n",
    "        title = str(class_names[truth_idx[0][0]]) + \" | \" + str(class_names[pred_idx])\n",
    "        title_obj = plt.title(title, fontdict={'fontsize':13})\n",
    "             \n",
    "        if pred_idx == truth_idx:\n",
    "            n_matches += 1\n",
    "            plt.setp(title_obj, color='g')\n",
    "        else:\n",
    "            plt.setp(title_obj, color='r')\n",
    "                 \n",
    "        acc = n_matches/(idx+1)\n",
    "    print(\"Prediction accuracy: \", int(100*acc)/100)\n",
    "     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed1cff9-b5df-4f35-ac95-96f943b1c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b91c76-9f6e-4b04-87f5-41b716d44ad0",
   "metadata": {},
   "source": [
    "##### <i style=\"color:purple\">**Exercise**: Visualize the confusion matrix.</i>\n",
    "\n",
    "A confusion matrix is a very common metric used to summarize a classification problem's results. The information is presented as a table or matrix where one axis represents the ground truth labels for each class, and the other axis represents the predicted labels from the network. The entries in the table represent the number of instances from an experiment (sometimes represented as percentages rather than counts). Generating a confusion matrix in TensorFlow is accomplished by calling the _tf.math.confusion_matrix()_ function, which takes two required arguments: the list of ground truth labels and the associated predicted labels.\n",
    "\n",
    "Be careful to compare labels that are only encoded in the same way (one-hot vs. label encoding !)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e739b-a286-496d-919a-930ab8164f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e54d04-a3b8-4f0c-96a7-42b919f29103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/cifar10/ConfusionMatrix.py\n",
    "# Generate predictions for the test dataset.\n",
    "predictions = model.predict(X_test)\n",
    " \n",
    "# For each sample image in the test dataset, select the class label with the highest probability.\n",
    "predicted_labels = [np.argmax(i) for i in predictions]\n",
    "\n",
    "# Convert one-hot encoded labels to integers.\n",
    "y_test_integer_labels = tf.argmax(y_test, axis=1)\n",
    " \n",
    "# Generate a confusion matrix for the test dataset.\n",
    "cm = tf.math.confusion_matrix(labels=y_test_integer_labels, predictions=predicted_labels)\n",
    " \n",
    "# Plot the confusion matrix as a heatmap.\n",
    "plt.figure(figsize=[14, 7])\n",
    "sn.heatmap(cm, annot=True, fmt='d', annot_kws={\"size\": 12})\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f315b69b-8348-4cf6-801e-2f853fabd66a",
   "metadata": {},
   "source": [
    "A confusion matrix is a content-rich representation of a model's class-level performance. It can be very instructive in better understanding the areas in which the model performs well and those in which it may have more difficulty. \n",
    "\n",
    "Here, for example, a few things stand out immediately. Two of the ten classes tend to be misclassified more than the others: Dogs and Cats. Specifically, when the input image is a cat (index 3), it is often misclassified as a dog, with 176 misclassified samples. When the input image is a dog (index 5), the most misclassified examples are cats, with 117 samples.\n",
    "Note also that the last row, representing trucks, is most often confused with cars. All these observations make intuitive sense, given the classes' similarity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
