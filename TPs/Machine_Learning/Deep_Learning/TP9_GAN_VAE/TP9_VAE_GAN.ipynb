{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ls4hgfTEHgGR"
   },
   "source": [
    "# <font size=\"7\">Modèles génératifs</font>\n",
    "\n",
    "<font size=\"3\">Statistique en grande dimension et Apprentissage profond.</font>\n",
    "\n",
    "--- \n",
    "\n",
    "Le but de ce TP est de manipuler les deux principaux exemples de modèles génératifs que nous avons vus en cours : les Auto-Encodeurs Variationnels ([VAE](#vae)) et les Réseaux Génératifs Antagonistes ([GAN](#gan))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import random as rd\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras.models as km\n",
    "import keras.layers as kl\n",
    "import keras.losses as kloss\n",
    "import keras.regularizers as kr\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Auto-Encodeurs Variationnels (VAE) <a id='vae'></a>\n",
    "\n",
    "Dans un premier temps, nous allons construire un auto-encodeur variationnel simple et appliquer celui-ci (i) à la génération de nombres et (ii) à la détection d'anomalies. Nous allons utiliser le même jeu de données que lors du précédent [TP](https://github.com/j-chevallier/ModIA-HDDL/blob/main/TP-8/TP8_Autoencodeurs.ipynb) sur les auto-encodeurs, à savoir [MNIST](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Jeu de données ([MNIST](http://yann.lecun.com/exdb/mnist/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('x_train.shape :',x_train.shape)\n",
    "print('x_test.shape :',x_test.shape)\n",
    "\n",
    "\n",
    "# Normalisation\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "\n",
    "# Vectorisation\n",
    "input_dim = np.prod(x_train.shape[1:])\n",
    "#n_train = x_train.shape[0]\n",
    "#n_test = x_test.shape[0]\n",
    "x_train = x_train.reshape((-1, input_dim))\n",
    "x_test = x_test.reshape((-1, input_dim))\n",
    "\n",
    "\n",
    "print('\\n === After vectorization ===')\n",
    "print('x_train.shape :',x_train.shape)\n",
    "print('x_test.shape :',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "idx = [rd.randint(0, x_train.shape[0]) for _ in range(0, n)]\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i+1)\n",
    "    plt.imshow(x_train[idx[i]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.grid(False)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Construction de l'auto-encodeur variationnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "batch_size = 100\n",
    "epochs = 25\n",
    "\n",
    "intermediate_dim = 512\n",
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodeur\n",
    "\n",
    "Nous construisons d'abord l'_encodeur_. Il est composé :\n",
    "\n",
    "1. D'une couche dense de `intermediate_dim = 512` neurones, de fonction d'activation $\\texttt{ReLu}$ ;\n",
    "2. De deux couches dense de `latent_dim = 2` neurones **au-dessus de la même 1ère couche**, de fonction d'activation linéaire. Ces deux couches vont produire les deux variables `z_mean` et `z_log_var` dans l'espace latent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Complétez le code ci-dessous._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vae/vae_encoder.py\n",
    "# Input layer\n",
    "inputs = kl.Input(shape=(input_dim,), name='encoder_input')\n",
    "\n",
    "# Dense layer from input layer\n",
    "x = kl.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "\n",
    "# Two dense layer that takes input from the same layer x\n",
    "z_mean = kl.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = kl.Dense(latent_dim, name='z_log_var')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable latente stochastique\n",
    "\n",
    "Nous allons utiliser l'astuce de reparamétrisation pour définir la variable latente aléatoire $z$ conditionnée par rapport l'image d'entrée $x$ selon la loi normale :\n",
    "$$ z\\vert x \\sim \\mathcal{N}\\big(\\mu_z(x), \\sigma_z(x)\\big) \\,. $$\n",
    "\n",
    "<br>\n",
    "<div><img src=\"img/vae_3.svg\" width=\"600px\" style=\"display:block; margin-left:auto; margin-right:auto;\"/></div>\n",
    "<br>\n",
    "\n",
    "L'astuce de reparamétrisation consiste à redéfinir $z$ comme suit :\n",
    "\n",
    "$$ z\\vert x=\\mu_z(x)+\\sigma_z(x)\\cdot\\varepsilon \\qquad\\text{avec}\\qquad \\varepsilon\\sim\\mathcal{N}(0,1) \\,. $$\n",
    "\n",
    "Ainsi, la dépendance entre $z$ et $x$ devient déterministe et _différentiable_. De plus, l'aléa de $z$, à $x$ fixé, est uniquement porté par $\\varepsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Afin de construire la dernière couche de l'encodeur (celle qui rend $z$), on commence par définir une fonction qui, prenant en entrée la sortie de la couche précédente `z_mean`, et `z_log_var`, génère un échantillon aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim))\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque** : L'usage de la fonction exponentielle permet de s'assurer de la positivité de l'écart-type. \n",
    "<!-- Autrement dit, on interprète la sortie de la couche `z_log_var` comme étant égale à $\\log\\big(\\sigma^2_z(x)\\big)$, et pas seulement $\\sigma_z(x)$. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On peut à présent définit une couche $\\texttt{keras}$ à partir de cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "\n",
    "z = kl.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Maintenant que nous avons définis toutes les couches nécessaires à l'élaboration de l'encodeur, on peut l'instancier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate encoder model\n",
    "\n",
    "encoder = km.Model(inputs, z, name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "#tf.keras.utils.plot_model(encoder, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Décodeur \n",
    "\n",
    "Le décodeur prend en entrée le vecteur $z$ (_i.e._ l'échantillon de la distribution latente définie par l'encodeur).  Il est ensuite composé de deux couches denses ayant les caractéristiques suivantes : \n",
    "\n",
    "* `intermediate_dim = 512` neurones, activation $\\texttt{ReLu}$.\n",
    "* `input_dim = 784` neurones, activation sigmoïde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Construisez ce décodeur._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vae/vae_decoder.py\n",
    "# build decoder model\n",
    "latent_inputs = kl.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = kl.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = kl.Dense(input_dim, activation='sigmoid')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = km.Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-Encodeur\n",
    "\n",
    "On peut maintenant associer l'encodeur et le décodeur pour définir notre auto-encodeur variationnel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Construire le VAE._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vae/vae.py\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs))\n",
    "vae = km.Model(inputs, outputs, name='vae_mlp')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction de perte\n",
    "\n",
    "Nous implémentons maintenant la fonction de perte \"VAE\" telle que décrite dans le cours :\n",
    "\n",
    "$$ \\mathcal{L}_{VAE} \\,=\\, \\mathcal{L}(x,\\hat{x}) \\,+\\, KL\\big(\\, q(z\\vert x) \\,\\vert\\vert\\, p(z) \\,\\big) \\,, $$\n",
    "\n",
    "où $\\mathcal{L}$ est une fonction de perte adaptée à notre problème entre l'image originale $x$ et l'image reconstruite $\\hat{x}$. Comme vu dans le TP précédent, notre choix se porte vers l'entropie croisée binaire. \n",
    "\n",
    "$KL$ désigne la divergence de Kullback-Leibler, et $p$ la distribution _a priori_ que l'on met sur la variable latente $z$. Étant donné que\n",
    "\n",
    "$$ z\\vert x\\sim\\mathcal{N}(\\mu_z(x),\\sigma_z(x)), $$\n",
    "\n",
    "nous choisissons comme _a priori_ pour $z$ la loi gaussienne centrée réduite : $z\\sim\\mathcal{N}(0,1)\\,$.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:teal\">\n",
    "    <b>Proposition</b> : Soit deux gaussiennes $\\, \\mathcal{N}_d(\\mu_p,\\Sigma_p) \\,$ et $\\, \\mathcal{N}_d(\\mu_q,\\Sigma_q)$. Alors leur divergence K-L est donnée par :\n",
    "</p>\n",
    "   \n",
    "<p style=\"color:teal\">\n",
    "$$ \n",
    "    KL\\big(\\, \\mathcal{N}_d(\\mu_q,\\Sigma_q) \\,\\vert\\vert\\, \\mathcal{N}_d(\\mu_p,\\Sigma_p) \\big) \\,=\\, \\frac12 \\left[\n",
    "    \\log\\frac{\\vert\\Sigma_p\\vert}{\\vert\\Sigma_q\\vert} - d + \\textrm{tr}\\big(\\Sigma_p^{-1}\\Sigma_q \\big) + \\big(\\mu_p -\n",
    "    \\mu_q\\big)^\\top \\Sigma_p^{-1}\\big(\\mu_p - \\mu_q\\big)\\right] \\,.\n",
    "$$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre cas, $\\, z\\sim\\mathcal{N}_2(0,I_2) \\,$ et $\\, z\\vert x\\sim\\mathcal{N}_2(\\mu_z(x),\\sigma_z(x)) \\,$. Ainsi, on a :\n",
    "\n",
    "$$ \n",
    "KL\\big(\\, q(z\\vert x) \\,\\vert\\vert\\, p(z) \\,\\big) \\,=\\, \\frac12 \\left[-\\log\\vert\\sigma_z(x)\\vert - 2 + \\text{tr} \\big(\\sigma_z(x)\\big) +\\mu_z(x)^\\top \\mu_z(x)\\right] \\,,\n",
    "$$\n",
    "\n",
    "ou encore :\n",
    "\n",
    "$$\n",
    "KL\\big(\\, q(z\\vert x) \\,\\vert\\vert\\, p(z) \\,\\big) \\,=\\, \\frac12 \\, \\sum_{j=1}^2 \\Big[ \\sigma_{z,j}(x) + \\mu_{z,j}^2(x) - 2 - \\log\\sigma_{z,j}(x) \\Big] \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : On utilisant cette dernière formulation, définir la fonction de perte du VAE._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vae/vae_loss.py\n",
    "reconstruction_loss = kloss.binary_crossentropy(inputs,outputs)\n",
    "reconstruction_loss *= 784\n",
    "\n",
    "kl_loss = 2 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement et Résultats\n",
    "\n",
    "Sur un ordinateur classique, sans GPU, l'entraînement prend environ 5 secondes par epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae.fit(x_train,\n",
    "        epochs=40,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant vérifier rapidement la performance du modèle en visualisant des exemples d'images de la base de test et de leur reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_decoded_vae = vae.predict(x_test, batch_size= batch_size)\n",
    "\n",
    "n = 10\n",
    "idx = [rd.randint(0, x_test.shape[0]) for _ in range(0, n)]\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[idx[i]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i+1 + n)\n",
    "    plt.imshow(x_test_decoded_vae[idx[i]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualisation de l'entraînement\n",
    "\n",
    "Afin de visualiser l'entraînement, nous aimerions afficher l'évolution des chiffres au cours de celui-ci.\n",
    "\n",
    "La fonction ci-dessous compile les codes définis précédement afin d'instancer un VAE, et sa perte associée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vae(intermediate_dim=512, latent_dim=2) :\n",
    "    # Encoder\n",
    "    inputs = kl.Input(shape=(input_dim,), name='encoder_input')\n",
    "    x = kl.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    z_mean = kl.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = kl.Dense(latent_dim, name='z_log_var')(x)\n",
    "    z = kl.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "    encoder = km.Model(inputs, z, name='encoder')\n",
    "\n",
    "    # Decoder\n",
    "    latent_inputs = kl.Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = kl.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = kl.Dense(input_dim, activation='sigmoid')(x)\n",
    "    decoder = km.Model(latent_inputs, outputs, name='decoder')\n",
    "    \n",
    "    # VAE\n",
    "    outputs = decoder(encoder(inputs))\n",
    "    vae = km.Model(inputs, outputs, name='vae_mlp')\n",
    "    \n",
    "    # Loss\n",
    "    reconstruction_loss = kloss.binary_crossentropy(inputs,outputs)\n",
    "    reconstruction_loss *= 784\n",
    "\n",
    "    kl_loss = 2 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    \n",
    "    return encoder, decoder, vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Sur le même ensemble d'image que précédement, regarder l'évolution des prédictions._\n",
    "\n",
    "On pourra par exemple afficher les prédictions pour les 10 premières epochs d'entraînement du VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vae/vae_seq.py\n",
    "n = 10\n",
    "m = 10\n",
    "\n",
    "# We keep the same data as before\n",
    "# idx = [rd.randint(0, x_test.shape[0]) for _ in range(0, n)]\n",
    "\n",
    "encoder_seq, decoder_seq, vae_seq = make_vae()\n",
    "vae_seq.compile(optimizer='adam')\n",
    "\n",
    "plt.figure(figsize=(2*n, 2*(m+2)))\n",
    "\n",
    "\n",
    "# display original\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(m+2, n, i+1)\n",
    "    plt.imshow(x_test[idx[i]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    \n",
    "print(\"=== Epoch 0/\"+str(m)+\" ===\")\n",
    "x_test_decoded_vae_seq = vae_seq.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "# display initialization\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(m+2, n, i+1 + n)\n",
    "    plt.imshow(x_test_decoded_vae_seq[idx[i]].reshape(28, 28))\n",
    "    plt.title('Init')\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    \n",
    "for j in range(m):\n",
    "    print(\"=== Epoch \"+str(j+1)+\"/\"+str(m)+\" ===\")  \n",
    "    vae_seq.fit(x_train,\n",
    "            epochs=1,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(x_test, None),\n",
    "            verbose=0)\n",
    "    \n",
    "    x_test_decoded_vae_seq = vae_seq.predict(x_test, batch_size=batch_size)\n",
    "    \n",
    "    # display reconstruction\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(m+2, n, i+1 + (j+2)*n)\n",
    "        plt.imshow(x_test_decoded_vae_seq[idx[i]].reshape(28, 28))\n",
    "        plt.title('Epoch '+str(j))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Classification de la variable latente\n",
    "\n",
    "Quelle est la distribution des différents chiffres sur l'espace latent ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### _**Exercice** : Pour répondre à cette question, représenter le nuage de points des chiffres encodés, selon la valeur de leur label._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vae/vae_classification.py\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "for i in range(10):\n",
    "    x_test_encoded_i = x_test_encoded[y_test==i]\n",
    "    plt.scatter(x_test_encoded_i[:, 0], x_test_encoded_i[:, 1], label=i)\n",
    "ax.grid(False)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Génération de nouveaux nombres\n",
    "\n",
    "On peut utiliser le caractère génératif du VAE pour générer de nouvelles données, en l'occurrence de nouveaux chiffres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Générer une nouvelle image._\n",
    "\n",
    "Pour cela, on pourra générer une réalisations de la variable latente aléatoire $z$ et utiliser le décodeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vae/vae_generation.py\n",
    "z_latent = np.expand_dims(np.random.normal(0,1,2), axis=0)\n",
    "x_generate = decoder.predict(z_latent)\n",
    "plt.imshow(x_generate[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également visualiser la variété associée à l'espace latent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15  # figure with 15x15 panels\n",
    "digit_size = 28\n",
    "\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = sc.stats.norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = sc.stats.norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample, verbose=0)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "#plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Détection d'anomalies\n",
    "\n",
    "Dans cette (avant-dernière) partie, nous allons voir comment les auto-encodeurs variationnels peuvent être utilisés pour réaliser de la détection d'anomalies.\n",
    "\n",
    "Pour cela, nous allons considérer que les images de 9 sont des valeurs aberrantes. Nous allons générer quatre jeux de données à partir des jeux de données d'entraînement et de test, à savoir :\n",
    "* Données d'entraînement et de test sans les 9,\n",
    "* Données d'entraînement et de test avec seulement les images de 9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_i = 9\n",
    "\n",
    "\n",
    "# Dataset without i=9\n",
    "x_train_ad = x_train[y_train!=outlier_i]\n",
    "n_train = x_train_ad.shape[0]-x_train_ad.shape[0]%100\n",
    "x_train_ad = x_train_ad[:n_train]\n",
    "\n",
    "x_test_ad =  x_test[y_test!=outlier_i]\n",
    "n_test = x_test_ad.shape[0]-x_test_ad.shape[0]%100\n",
    "x_test_ad = x_test_ad[:n_test]\n",
    "\n",
    "\n",
    "# Dataset with only i=9\n",
    "anomaly_train = x_train[y_train==outlier_i]\n",
    "n_train = anomaly_train.shape[0]-anomaly_train.shape[0]%100\n",
    "anomaly_train = anomaly_train[:n_train]\n",
    "\n",
    "anomaly_test =  x_test[y_test==outlier_i]\n",
    "n_test = anomaly_test.shape[0]-anomaly_test.shape[0]%100\n",
    "anomaly_test = anomaly_test[:n_test]\n",
    "\n",
    "\n",
    "x_train_ad.shape, anomaly_train.shape, x_test_ad.shape, anomaly_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Construire un VAE pour la détection du chiffre 9_.\n",
    "\n",
    "Pour cela :\n",
    "1. Construisez un VAE similaire à celui que nous avons étudié, et entraîner sur le jeu de données ne contenant pas le chiffre 9.\n",
    "2. Puis, visualisez le résultat de la reconstruction sur le jeu de données composés des chiffres de 0 à 8 d'une part, et sur le jeu de données composés du chiffre 9 uniquement d'autre part. \n",
    "3. Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load solutions/vae/vae_anomaly.py\n",
    "encoder_ad, decoder_ad, vae_ad = make_vae()\n",
    "vae_ad.compile(optimizer='adam')\n",
    "\n",
    "vae_ad.fit(x_train_ad, \n",
    "           epochs = 40, \n",
    "           batch_size = batch_size, \n",
    "           validation_data = (x_test_ad, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images décodées par le VAE \n",
    "\n",
    "Utilisons à présent notre VAE sur l'ensemble de données de test avec les nombres connus (0 à 8) d'une part, et sur les valeurs aberrantes (9) d'autre part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Données d'entraînement régulières"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vae/vae_anomaly_regular.py\n",
    "x_test_decoded_ad = vae_ad.predict(x_test_ad, batch_size=batch_size)\n",
    "\n",
    "n = 10\n",
    "idx = [rd.randint(0, x_test_ad.shape[0]) for _ in range(0, n)]\n",
    "\n",
    "plt.figure(figsize=(2*n, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test_ad[idx[i]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i+1 + n)\n",
    "    plt.imshow(x_test_decoded_ad[idx[i]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Données aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vae/vae_anomaly_outliers.py\n",
    "anomaly_decoded = vae_ad.predict(anomaly_test, batch_size=batch_size)\n",
    "\n",
    "n = 10\n",
    "idx = [rd.randint(0, anomaly_test.shape[0]) for _ in range(0, n)]\n",
    "\n",
    "plt.figure(figsize=(2*n, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(anomaly_test[idx[i]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i+1 + n)\n",
    "    plt.imshow(anomaly_decoded[idx[i]].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Détection d'anomalies à l'aide de la représentation latente\n",
    "\n",
    "En réalisant un clustering \"Normal-vs-Outliers\" dans l'espace latent, on peut espérer détecter les anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Comparer la distribution des encodages des données régulières et aberrantes._\n",
    "\n",
    "Pour cela, on pourra visualiser le nuage de points correspondant au données normales d'une part, et aux données aberrantes d'autre part, sur me même graphique. Peut-on mettre facilement en place une technique de clustering ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/vae/vae_anomaly_reg_vs_out.py\n",
    "x_test_encoded_ad = encoder_ad.predict(x_test_ad, batch_size=batch_size)\n",
    "anomaly_encoded = encoder_ad.predict(anomaly_test, batch_size=batch_size)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = plt.subplot(1,1,1)\n",
    "    \n",
    "plt.scatter(x_test_encoded_ad[:, 0], x_test_encoded_ad[:, 1], color=\"skyblue\", alpha=.5, label=\"Normal\")\n",
    "plt.scatter(anomaly_encoded[:, 0], anomaly_encoded[:, 1], color=\"purple\", alpha=.5, label=\"Outliers\") \n",
    "    \n",
    "ax.grid(False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vouloir regarder une transformation de l'espace latent, par exemple en utilisant l'algorithme TSNE non linéaire, pour voir si la séparation est alors plus franche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "latent_space_tsne = TSNE(2, verbose = True, n_iter = 500)\n",
    "xa_tsne = latent_space_tsne.fit_transform(np.concatenate([x_test_encoded_ad, anomaly_encoded],0))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "plt.scatter(xa_tsne[:,0], xa_tsne[:,1],\n",
    "            color=(['skyblue']*x_test_encoded_ad.shape[0])+['purple']*anomaly_encoded.shape[0], alpha = 0.5)\n",
    "\n",
    "ax.grid(False)\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution de l'erreur de reconstruction\n",
    "\n",
    "Pour évaluer le fonctionnement de la détection des images 9, vérifions la distribution des différentes erreurs $l_2$ entre l'image originale et leur image reconstruite pour trois types d'images :\n",
    "\n",
    "* Images de nombre connu (0 à 8),\n",
    "* Images aberrantes (9),\n",
    "* Images générées de façon complètement aléatoire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Construisez un histogramme des erreurs de reconstruction pour chacune des trois situation._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vae_ad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %load solutions/vae/vae_hist.py\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Regular data\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m x_test_decoded_ad \u001b[38;5;241m=\u001b[39m \u001b[43mvae_ad\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(x_test_ad, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m      4\u001b[0m mse_normal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(x_test_ad\u001b[38;5;241m-\u001b[39mx_test_decoded_ad, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Outliers data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vae_ad' is not defined"
     ]
    }
   ],
   "source": [
    "# %load solutions/vae/vae_hist.py\n",
    "# Regular data\n",
    "x_test_decoded_ad = vae_ad.predict(x_test_ad, batch_size=batch_size)\n",
    "mse_normal = np.linalg.norm(x_test_ad-x_test_decoded_ad, axis=1)\n",
    "\n",
    "# Outliers data\n",
    "anomaly_decoded = vae_ad.predict(anomaly_test, batch_size=batch_size)\n",
    "mse_outliers = np.linalg.norm(anomaly_test-anomaly_decoded, axis=1)\n",
    "\n",
    "# Random data\n",
    "x_random = np.random.uniform(size=(1000, 784),low=0.0, high=1.0)\n",
    "x_random_decoded =  vae_ad.predict(x_random, batch_size=batch_size)\n",
    "mse_random = np.linalg.norm(x_random-x_random_decoded, axis=1)\n",
    "\n",
    "\n",
    "# Histograms \n",
    "fig = plt.figure(figsize=(9,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "sns.histplot(data=mse_normal, stat='density', color=\"skyblue\", ax=ax, label=\"Normal\", kde=True)\n",
    "sns.histplot(data=mse_outliers, stat='density', color=\"purple\", ax=ax, label=\"Outliers\", kde=True)\n",
    "sns.histplot(data=mse_random, stat='density', color=\"teal\", ax=ax, label=\"Random\", kde=True)\n",
    "\n",
    "ax.set_xlabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Question** : Que pouvez-vous dire de la reconstruction des erreurs dans les différents cas ? Concluez quant à la performance du VAE pour détecter les anomalies._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également \"mesurer\" la performance du d'un tel classifieur à l'aide d'une courbe ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "mse_score = np.concatenate([mse_normal,mse_outliers], 0)\n",
    "true_label = [0]*x_test_ad.shape[0] + [1]*anomaly_test.shape[0]\n",
    "\n",
    "if roc_auc_score(true_label, mse_score)<0.5 :\n",
    "    mse_score *= -1\n",
    "    \n",
    "fpr, tpr, thresholds = roc_curve(true_label, mse_score)\n",
    "auc_score = roc_auc_score(true_label, mse_score)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (9,5))\n",
    "\n",
    "ax.plot(fpr, tpr, 'c.-', label = 'ROC Curve {:2.2f}'.format(auc_score))\n",
    "ax.plot(fpr, fpr, 'k-', label = 'Random Guessing')\n",
    "\n",
    "ax.set_xlabel('False positive rate')\n",
    "ax.set_ylabel('True positive rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clairement, le résultat n'est pas très concluant ici. On peut essayer d'améliorer l'architecture de notre VAE pour améliorer la performance !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Auto-encodeurs variationnels et convolutifs\n",
    "\n",
    "**Exercice (Pour aller plus loin)** : Nous avons vu comment construire un VAE et comment l'utiliser pour générer de nouvelles images et détecter des anomalies. Les VAE utilisés jusqu'à présent n'utilisent que des couches denses (MLP), ce qui peut expliquer leur manque d'efficacité pour la détection d'anomalies. \n",
    "\n",
    "Utilisez des couches CNN pour construire un VAE convolutif et testez les différentes applications (générer des images et détecter des anomalies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseaux Génératifs Antagonistes (GAN) <a id='gan'></a>\n",
    "\n",
    "Le but de cette seconde partie est de manipuler des réseaux antagonistes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Réseau \"jouet\" en dimension 1\n",
    "\n",
    "Compte-tenu de la lenteur d'entraînement des GANs, pour arriver à faire tourner un premier réseau dans la durée impartie pa TP, nous commençons par considérer un simple réseau unidimensionnel sur des données jouets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jeu de données\n",
    "\n",
    "La première étape consiste à créer un jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Construisez un jeu de données unidimensionnel._\n",
    "\n",
    "Pour cela :\n",
    "1. Choisissez une fonction numérique $f$, par exemple la fonction $f\\colon x\\mapsto x^2$,\n",
    "2. Générer $n=100$ points répartis _aléatoirement_ le long de la courbe représentative de $f$,\n",
    "3. Contrôlez la bonne dispersion des points à l'aide d'un nuage de points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/gan/gan_data.py\n",
    "n = 100\n",
    "f = lambda x: x*x\n",
    "\n",
    "def generate_samples(fun=f,n=100):    \n",
    "    # generate random inputs in [-0.5, 0.5]\n",
    "    x1 = np.random.rand(n) - 0.5\n",
    "    # generate outputs x^2 (quadratic)\n",
    "    x2 = fun(x1)\n",
    "    # stack arrays\n",
    "    x1 = x1.reshape(n, 1)\n",
    "    x2 = x2.reshape(n, 1)\n",
    "    return np.hstack((x1, x2))\n",
    " \n",
    "    \n",
    "# generate samples\n",
    "x = generate_samples()\n",
    "\n",
    "# plot samples\n",
    "fig, ax = plt.subplots(1, 1, figsize = (8,5))\n",
    "plt.scatter(x[:, 0], x[:, 1])\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminateur\n",
    "\n",
    "La prochaine étape consiste à définir le discriminateur. \n",
    "\n",
    "Le discriminateur est un classifieur qui prend en entrée des données (réelles ici) et cherche à déterminer s'il s'agit d'une donnée réelle ou non. On va utiliser à cet effet un simple perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Construisez un discriminateur._\n",
    "\n",
    "On pourra utiliser un MPL à une couche cachée de 25 neurones. \n",
    "<!-- dont les poids sont initialisés selon la méthode [He](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeNormal). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/gan/gan_discriminator.py\n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(n_inputs=2):\n",
    "    discriminator = keras.Sequential(name='discriminator')\n",
    "    discriminator.add(kl.Dense(25, activation='relu', input_dim=n_inputs, kernel_initializer='he_uniform'))  #kernel_initializer='he_uniform'\n",
    "    discriminator.add(kl.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # compile model\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return discriminator\n",
    " \n",
    "    \n",
    "# define the discriminator model\n",
    "discriminator = define_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation de la performance du discriminateur\n",
    "\n",
    "Avant de construire notre GAN, on souhaite vérifier que ce discriminateur fait un bon classifieur (vu la tâche, le suspens n'est pas vraiment à son paroxysme...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Entraîner le discriminateur._\n",
    "\n",
    "Pour cela, on pourra commencer par définir une fonction `generate_fake_samples` qui génèrent $n=100$ faux points, vivant dans le même espace que les vrais, et labellisés 0. On adaptera cette fonction par la suite pour qu'elle génère des faux points à partir de l'espace latent. \n",
    "\n",
    "Réaliser l'entraînement en énumérant à la main les epochs et un utilisant la fonction [`train_on_batch`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#train_on_batch) de $\\texttt{keras}$. Pour cela, compléter le code fourni. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/gan/gan_generate_real_samples.py\n",
    "def generate_real_samples(n=100):\n",
    "    x = generate_samples(n=n)\n",
    "    y = np.ones((n, 1))\n",
    "    return x, y\n",
    "\n",
    "def generate_fake_samples(n=100):\n",
    "    x = 2*np.random.rand(n,2)-1\n",
    "    y = np.zeros((n, 1))\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# generate samples\n",
    "x_real, y_real = generate_real_samples()\n",
    "x_fake, y_fake = generate_fake_samples()\n",
    "\n",
    "# plot samples\n",
    "fig, ax = plt.subplots(1, 1, figsize = (8,5))\n",
    "\n",
    "plt.scatter(x_real[:, 0], x_real[:, 1], color=\"purple\", alpha=.5, label=\"Real data\")\n",
    "plt.scatter(x_fake[:, 0], x_fake[:, 1], color=\"skyblue\", alpha=.5, label=\"Fake data\") \n",
    "\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/gan/gan_train_discriminator.py\n",
    "def train_discriminator(model, n_epochs=1000, n_batch=128):\n",
    "    ''' Train the discriminator model '''\n",
    "    \n",
    "    half_batch = int(n_batch / 2)\n",
    "    \n",
    "    # run epochs manually\n",
    "    for step in range(n_epochs):\n",
    "        # generate real and fake examples\n",
    "        x_real, y_real = generate_real_samples(half_batch)\n",
    "        x_fake, y_fake = generate_fake_samples(half_batch)\n",
    "        \n",
    "        # update model\n",
    "        model.train_on_batch(x_real, y_real)\n",
    "        model.train_on_batch(x_fake, y_fake)\n",
    "        \n",
    "        # evaluate the model\n",
    "        _, acc_real = model.evaluate(x_real, y_real, verbose=0)\n",
    "        _, acc_fake = model.evaluate(x_fake, y_fake, verbose=0)\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print('Iter {:d}/{:d}'.format(step,n_epochs))\n",
    "            print('Accuracy on real data: {:2.4f}  -  Accuracy on fake data: {:2.4f}\\n'.format(acc_real, acc_fake))\n",
    "        \n",
    "        \n",
    "# define the discriminator model\n",
    "discriminator = define_discriminator()\n",
    "\n",
    "# fit the model\n",
    "train_discriminator(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Générateur\n",
    "\n",
    "On s'intéresse à présent au générateur. Le modèle générateur prend en entrée un point de l'espace latent et génère un nouvel échantillon. \n",
    "\n",
    "Nous choisissons de définit un _petit_ espace latent de cinq dimensions et utilisons l'approche standard de la littérature sur les GAN consistant à utiliser une distribution gaussienne pour chaque variable de l'espace latent. Aussi, nous générons de nouvelles entrées en tirant des nombres aléatoires d'une distribution gaussienne centrée réduite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Construisez un générateur._\n",
    "\n",
    "On pourra utiliser un MPL à une couche cachée de 15 neurones. \n",
    "<!-- dont les poids sont initialisés selon la méthode [He](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeNormal). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/gan/gan_generator.py\n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim=5, n_outputs=2):\n",
    "    generator = keras.Sequential(name='generator')\n",
    "    generator.add(kl.Dense(15, activation='relu', input_dim=latent_dim, kernel_initializer='he_uniform'))\n",
    "    generator.add(kl.Dense(n_outputs, activation='linear'))\n",
    "    return generator\n",
    "\n",
    "# define the generator model\n",
    "generator = define_generator()\n",
    "\n",
    "# summarize the model\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple d'utilisation du générateur\n",
    "\n",
    "Avant de construire notre GAN à proprement parlé, nous allons voir comment utiliser ce générateur pour générer de nouveaux éléments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Modifier la fonction `generate_fake_samples` définie précédemment de sorte à ce qu'elle génère $n$ faux échantillons à l'aide du générateur._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/gan/gan_generate_fake_samples.py\n",
    "def generate_fake_samples(model, latent_dim=5, n=100):\n",
    "    '''use the generator to generate n fake examples'''\n",
    "    \n",
    "    # generate n points in the latent space, according to a Gaussian distribution\n",
    "    x_latent = np.random.randn(n,latent_dim)\n",
    "\n",
    "    # predict and label outputs\n",
    "    x = model.predict(x_latent)\n",
    "    y = np.zeros((n, 1))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the generator model\n",
    "generator = define_generator()\n",
    "\n",
    "# generate samples\n",
    "x_real, y_real = generate_real_samples()\n",
    "x_fake, y_fake = generate_fake_samples(generator)\n",
    "\n",
    "# plot samples\n",
    "fig, ax = plt.subplots(1, 1, figsize = (8,5))\n",
    "\n",
    "plt.scatter(x_real[:, 0], x_real[:, 1], color=\"purple\", alpha=.5, label=\"Real data\")\n",
    "plt.scatter(x_fake[:, 0], x_fake[:, 1], color=\"skyblue\", alpha=.5, label=\"Fake data\") \n",
    "\n",
    "ax.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme le générateur n'a pas été entraîné, les points générés sont essentiellement aléatoires, comme nous nous y attendions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau génératif antagoniste\n",
    "\n",
    "Les poids du générateur doivent être mis à jour en fonction des performances du modèle discriminateur : Lorsque le discriminateur détecte bien les faux échantillons, le générateur doit être fortement mis à jour ; Au contraire, lorsque le discriminateur est confus lors de la détection des faux échantillons, le modèle du générateur sera moins mis à jour. \n",
    "\n",
    "Autrement dit, il y a inter-dépendance dans la mise-à-jour de ces deux réseaux, comme vu en cours.\n",
    "\n",
    "<br>\n",
    "\n",
    "Chacun des réseaux à son rôle propre :\n",
    "\n",
    "* Seul le _discriminateur_ est concerné par la distinction entre vrais et faux exemples. <br>\n",
    "Ainsi, le modèle discriminateur peut être entraîné de manière **autonome** sur des exemples de chaque type.\n",
    "\n",
    "* Le _générateur_ ne s'intéresse qu'aux performances du discriminateur sur les faux exemples. <br>\n",
    "Nous marquons donc toutes les couches du discriminateur comme non entraînables lorsqu'elles font partie du modèle GAN afin qu'elles ne puissent pas être mises à jour et surentraînées sur des exemples faux.\n",
    "\n",
    "Concrètement, on définit le GAN comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    '''define the combined generator and discriminator model, i.e. the GAN model'''\n",
    "    \n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    # Connect generator and discriminator\n",
    "    gan = keras.Sequential()\n",
    "    gan.add(generator)\n",
    "    gan.add(discriminator)\n",
    "    \n",
    "    # compile model\n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return gan\n",
    "\n",
    "\n",
    "discriminator = define_discriminator()\n",
    "generator = define_generator(latent_dim=5)\n",
    "\n",
    "gan = define_gan(generator, discriminator)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a un autre changement **important** à faire, lors de l'entraînement du _générateur_ dans le GAN \"assemblé\". Nous voulons faire croire au discriminateur pense que les échantillons produits par le générateur sont réels, et non faux (et le forcer à ne pas se laisser duper !). Par conséquent, lorsque le générateur est entraîné dans le GAN complet, nous devons marquer les échantillons générés comme réels (classe 1).\n",
    "\n",
    "Nous pouvons imaginer que le discriminateur classera ensuite les échantillons générés comme faux (classe 0) ou avec une faible probabilité d'être réels (0,3 ou 0,5). Le processus de rétropropagation du gradient utilisé pour mettre à jour les poids du générateur considérera alors qu'il s'agit d'une erreur importante et mettra à jour ses poids (attention : uniquement les poids du générateur ici) pour corriger cette erreur, ce qui devrait permettre au générateur de mieux générer de faux échantillons plausibles.\n",
    "\n",
    "Ainsi, pour entraîner uniquement le générateur, on utiliserait une fonction du type :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(gan, latent_dim=5, n_epochs=10000, n_batch=128):\n",
    "    '''train the generator'''\n",
    "    \n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # prepare points in latent space as input for the generator\n",
    "        x = np.random.randn(n_batch,latent_dim)\n",
    "        # create inverted labels for the fake samples\n",
    "        y = np.ones((n_batch, 1))\n",
    "        # update the generator via the discriminator's error\n",
    "        gan.train_on_batch(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette seule fonction ne permet évidement pas d'entraîner le GAN car l'optimisation des poids entre générateur et discriminateur doit se faire de manière simultanée. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _**Exercice** : Entraîner le GAN._\n",
    "\n",
    "1. Afin de visualiser l'avancement de l'entraînement, définissez une fonction qui permet de visualiser sur un même graphique données réelles et données générées par le générateur.\n",
    "\n",
    "2. Définissez une fonction `train` qui permet d'entraîner le GAN. L'entraînement sera réalisé à la main, en énumérant les différentes epochs. On pourra utiliser tout ou partie des fonctions `train_discriminator` et `train_generator`. Visualiser périodiquement l'avancement au cours du processus d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/gan/gan_visualize_performance.py\n",
    "def visualize_performance(step, generator, discriminator, latent_dim=5, n_epochs=10000, n=100):\n",
    "    '''Evaluate the discriminator and plot real and fake points'''\n",
    "    \n",
    "    # Generate real and fake samples\n",
    "    x_real, y_real = generate_real_samples(n)\n",
    "    x_fake, y_fake = generate_fake_samples(generator, latent_dim, n)\n",
    "    \n",
    "    # evaluate discriminator\n",
    "    _, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n",
    "    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Iter {:d}/{:d}'.format(step,n_epochs))\n",
    "    print('Accuracy on real data: {:2.4f}  -  Accuracy on fake data: {:2.4f}\\n'.format(acc_real, acc_fake))\n",
    "     \n",
    "    # plot samples\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "\n",
    "    plt.scatter(x_real[:, 0], x_real[:, 1], color=\"purple\", alpha=.5, label=\"Real data\")\n",
    "    plt.scatter(x_fake[:, 0], x_fake[:, 1], color=\"skyblue\", alpha=.5, label=\"Fake data\") \n",
    "\n",
    "    ax.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/gan/gan_train.py\n",
    "def train(gan, generator, discriminator, latent_dim=5, n_epochs=10000, n_batch=128, n_eval=200):\n",
    "    '''train the generator and discriminator'''\n",
    "    \n",
    "    # determine half the size of one batch, for updating the discriminator\n",
    "    half_batch = int(n_batch / 2)\n",
    "    \n",
    "    # manually enumerate epochs\n",
    "    for step in range(n_epochs+1):\n",
    "        # prepare real and fake samples\n",
    "        x_real, y_real = generate_real_samples(half_batch)\n",
    "        x_fake, y_fake = generate_fake_samples(generator, latent_dim, half_batch)\n",
    "        \n",
    "        # update discriminator\n",
    "        discriminator.train_on_batch(x_real, y_real)\n",
    "        discriminator.train_on_batch(x_fake, y_fake)\n",
    "        \n",
    "        # points in latent inverted labels, as input for the generator\n",
    "        x = np.random.randn(n_batch,latent_dim)\n",
    "        y = np.ones((n_batch, 1))\n",
    "        \n",
    "        # update the generator via the discriminator's error\n",
    "        gan.train_on_batch(x, y)\n",
    "        \n",
    "        # evaluate the model every n_eval epochs\n",
    "        if step % n_eval == 0:\n",
    "            visualize_performance(step, generator, discriminator, latent_dim, n_epochs, half_batch)\n",
    "        \n",
    "        # Training step\n",
    "        if (step+1) % 10 == 0:\n",
    "            print('.', end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load solutions/gan/gan_fit.py\n",
    "latent_dim = 5\n",
    "n_inputs = 2\n",
    "n_outputs = 2\n",
    "\n",
    "n_epochs = 10000\n",
    "n_batch = 128\n",
    "n_eval = 2000\n",
    "\n",
    "\n",
    "# create the GAN model\n",
    "discriminator = define_discriminator(n_inputs)\n",
    "generator = define_generator(latent_dim, n_outputs)\n",
    "gan = define_gan(generator, discriminator)\n",
    "\n",
    "# train model\n",
    "train(gan, generator, discriminator, latent_dim, n_epochs, n_batch, n_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Réseau antagoniste pour générer de nouveaux chiffres\n",
    "\n",
    "Le réseau ci-après permet d'illustrer le fonctionnement d'un GAN sur un exemple (un peu) plus intéressant : la base de données [MNIST](http://yann.lecun.com/exdb/mnist/). \n",
    "\n",
    "Malgré la simplicité su problème, l'entraînement est **long**. Ceci illustre bien à quel point les GANs sont _très_ longs et compliqués à entraîner...\n",
    "\n",
    "Le code présenté ci-dessous est adapté de l'exemple décrit dans [la documentation de $\\texttt{keras}$](https://keras.io/guides/writing_a_training_loop_from_scratch/#using-the-gradienttape-a-first-endtoend-example). On commence par définir les réseaux discriminateur et générateur, en suivant les recommandations de DCGAN (activation $\\texttt{LeakyReLU}$, $\\texttt{stride}$, $\\texttt{Batch normalization}$, activation de sortie $\\texttt{tanh}$ pour le générateur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        kl.Input(shape=(28, 28, 1)),\n",
    "        kl.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        kl.BatchNormalization(momentum = 0.5),\n",
    "        kl.LeakyReLU(alpha=0.2),\n",
    "        kl.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        kl.BatchNormalization(momentum = 0.5),\n",
    "        kl.LeakyReLU(alpha=0.2),\n",
    "        kl.GlobalMaxPooling2D(),\n",
    "        kl.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        kl.Input(shape=(latent_dim,)),\n",
    "        kl.Dense(7 * 7 * 128),        \n",
    "        kl.BatchNormalization(momentum = 0.5),\n",
    "        kl.LeakyReLU(alpha=0.2),\n",
    "        kl.Reshape((7, 7, 128)),\n",
    "        kl.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        kl.BatchNormalization(momentum = 0.5),\n",
    "        kl.LeakyReLU(alpha=0.2),\n",
    "        kl.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        kl.BatchNormalization(momentum = 0.5),\n",
    "        kl.LeakyReLU(alpha=0.2),\n",
    "        kl.Conv2D(1, (7, 7), padding=\"same\", activation=\"tanh\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZ0FTcu6yl56"
   },
   "source": [
    "Le code suivant décrit ce qui se passe à chaque itération de l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RnxhJX_KJxF"
   },
   "outputs": [],
   "source": [
    "# Instanciation de deux optimiseurs, l'un pour le discrimnateur et l'autre pour le générateur\n",
    "d_optimizer = keras.optimizers.Adam(learning_rate=0.0008)\n",
    "g_optimizer = keras.optimizers.Adam(learning_rate=0.0004)\n",
    "\n",
    "# Instanciation d'une fonction de coût entropie croisée\n",
    "loss_fn = kloss.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "# La fonction prend en entrée un mini-batch d'images réelles\n",
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    \n",
    "    # ENTRAINEMENT DU DISCRIMINATEUR\n",
    "    # Échantillonnage d’un mini-batch de bruit\n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "    # Création d'un mini-batch d'images générées à partir du bruit\n",
    "    generated_images = generator(random_latent_vectors)\n",
    "    # Échantillonnage d’un mini-batch de données combinant images générées et réelles\n",
    "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "    # Création des labels associés au mini-batch de données créé précédemment\n",
    "    # Pour l'entraînement du discriminateur :\n",
    "    #   - les données générées sont labellisées \"0\" MAIS EN FAIT ICI 1 !!! \n",
    "    #   - les données réelles sont labellisées \"1\" MAIS EN FAIT ICI O !!!!\n",
    "    labels = tf.concat(\n",
    "        [tf.ones((batch_size, 1)), tf.zeros((real_images.shape[0], 1))], axis=0\n",
    "    )\n",
    "    # Astuce du \"Label Smoothing\"\n",
    "    labels += 0.05 * tf.random.uniform(labels.shape)\n",
    "\n",
    "    # Entraînement du discriminateur\n",
    "    with tf.GradientTape() as tape:\n",
    "        # L'appel d'un modèle (ici discriminator) à l'intérieur de Tf.GradientTape\n",
    "        # permet de récupérer les gradients pour faire la mise à jour\n",
    "\n",
    "        # Prédiction du discriminateur sur notre batch d'images réelles et générées\n",
    "        predictions = discriminator(combined_images)\n",
    "        # Calcul de la fonction de coût\n",
    "        d_loss = loss_fn(labels, predictions)\n",
    "    # Récupération des gradients de la fonction de coût par rapport aux paramètres du discriminateur\n",
    "    grads = tape.gradient(d_loss, discriminator.trainable_weights)\n",
    "    # Mise à jour des paramètres par l'optimiseur grâce aux gradients de la fonction de coût\n",
    "    d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "\n",
    "    # ENTRAINEMENT DU GENERATEUR\n",
    "    # Échantillonnage d’un mini-batch de bruit\n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "    # Création des labels associés au mini-batch de données créé précédemment\n",
    "    # Pour l'entraînement du générateur :\n",
    "    #   - les données générées sont labellisées \"1\" MAIS EN FAIT ICI 0 !!! \n",
    "    misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "    # Entraînement du générateur sans toucher aux paramètres du discriminateur !\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = discriminator(generator(random_latent_vectors))\n",
    "        g_loss = loss_fn(misleading_labels, predictions)\n",
    "    grads = tape.gradient(g_loss, generator.trainable_weights)\n",
    "    g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "    return d_loss, g_loss, generated_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "all1LAF92h1u"
   },
   "source": [
    "Il reste à écrire l'algorithme final qui va faire appel au code d'itération écrit précédemment.\n",
    "\n",
    "Au début de la formation, les images générées ressemblent à du bruit aléatoire. Au fur et à mesure que la formation progresse, les chiffres générés sembleront de plus en plus réels. Après environ 20 époques, on peut voir \"apparaître\" des chiffres qui semblent réalistes. Une 50aine d'epochs est nécessaire pour qu'ils ressemblent aux chiffres MNIST. Cela peut prendre environ une minute/epoch avec les paramètres par défaut de Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1598069,
     "status": "ok",
     "timestamp": 1634137002527,
     "user": {
      "displayName": "Arthur Renaudeau",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04270738073315590391"
     },
     "user_tz": -120
    },
    "id": "lQJWoazN2pwd",
    "outputId": "a7253e12-8219-419a-d139-0c187a88bae4"
   },
   "outputs": [],
   "source": [
    "# Préparation de la base de données : on utilise toutes les images (entraînement + test) de MNIST\n",
    "batch_size = 64\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_digits = (all_digits.astype(\"float32\")-127.5) / 127.5 # Images normalisées\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "epochs = 20  # Une 20aine d'epochs est nécessaire pour voir des chiffres qui semblent réalistes\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart epoch\", epoch)\n",
    "\n",
    "    for step, real_images in enumerate(dataset):\n",
    "        # Descente de gradient simultanée du discrimnateur et du générateur\n",
    "        d_loss, g_loss, generated_images = train_step(real_images)\n",
    "\n",
    "        # Affichage régulier d'images générées.\n",
    "        if step % 200 == 0:\n",
    "            # Métriques\n",
    "            print(\"Perte du discriminateur à l'étape %d: %.2f\" % (step, d_loss))\n",
    "            print(\"Perte du générateur à l'étape %d: %.2f\" % (step, g_loss))\n",
    "\n",
    "            plt.figure(figsize=(20, 4))\n",
    "            for i in range(10):\n",
    "              plt.subplot(1,10, i+1)\n",
    "              plt.imshow(generated_images[i, :, :, 0]*128+128, cmap='gray')\n",
    "              \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwIc9354oNIV"
   },
   "source": [
    "---\n",
    "## Réseau antagoniste pour le transfert de style (pour aller plus loin)\n",
    "\n",
    "Prenez le temps de lire et de comprendre le code ci-dessus pour les chiffres MNIST. Observez attentivement l'évolution des métriques ainsi que les images générées au cours de l'entraînement. L'objectif de cette partie est d'abord de vous fournir un exemple de code implémentant les GANs, mais surtout de vous faire sentir la difficulté d'entraîner ces modèles.\n",
    "\n",
    "Dans la suite du TP, nous vous fournissons ci-dessous un code de chargement de la base de données de visages *Labelled Faces in the Wild*. Votre objectif est donc d'adapter le code précédent pour générer non plus des chiffres mais des visages.\n",
    "\n",
    "Quelques précisions importantes, et indications : \n",
    "\n",
    "*   MNIST est une base de données d'images noir et blanc de dimension 28 $\\times$ 28, LFW est une base de données d'images couleur de dimension 32 $\\times$ 32 $\\times$ 3 ;\n",
    "*   La diversité des visages est bien plus grande que celle des chiffres. Votre générateur doit donc être un peu plus complexe que celui utilisé ici (plus de couches, et/ou plus de filtres par exemple) ;\n",
    "*   Pour faire fonctionner ce second exemple, il pourrait être nécessaire de remettre en cause certaines des bonnes pratiques présentées en cours et utilisées dans le code de MNIST..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohexDvCYrahC"
   },
   "source": [
    "Le code suivant affiche des exemples d'images de la base de test et de leur reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712,
     "referenced_widgets": [
      "ed6b4e805d7a489fadc0a35d3bb0d1ed"
     ]
    },
    "executionInfo": {
     "elapsed": 28229,
     "status": "ok",
     "timestamp": 1634139513614,
     "user": {
      "displayName": "Arthur Renaudeau",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04270738073315590391"
     },
     "user_tz": -120
    },
    "id": "Ot-zkfDBQUkl",
    "outputId": "32d81c92-70e6-427e-f897-32e1c0c89ee5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tarfile, tqdm, cv2, os\n",
    "\n",
    "# Télécharger les données de la base de données \"Labelled Faces in the Wild\"\n",
    "!wget http://www.cs.columbia.edu/CAVE/databases/pubfig/download/lfw_attributes.txt\n",
    "!wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz\n",
    "!wget http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
    "  \n",
    "ATTRS_NAME = \"lfw_attributes.txt\"\n",
    "IMAGES_NAME = \"lfw-deepfunneled.tgz\"\n",
    "RAW_IMAGES_NAME = \"lfw.tgz\"\n",
    "\n",
    "def decode_image_from_raw_bytes(raw_bytes):\n",
    "    img = cv2.imdecode(np.asarray(bytearray(raw_bytes), dtype=np.uint8), 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def load_lfw_dataset(\n",
    "        use_raw=False,\n",
    "        dx=80, dy=80,\n",
    "        dimx=45, dimy=45):\n",
    "\n",
    "    # Read attrs\n",
    "    df_attrs = pd.read_csv(ATTRS_NAME, sep='\\t', skiprows=1)\n",
    "    df_attrs = pd.DataFrame(df_attrs.iloc[:, :-1].values, columns=df_attrs.columns[1:])\n",
    "    imgs_with_attrs = set(map(tuple, df_attrs[[\"person\", \"imagenum\"]].values))\n",
    "\n",
    "    # Read photos\n",
    "    all_photos = []\n",
    "    photo_ids = []\n",
    "\n",
    "    # tqdm in used to show progress bar while reading the data in a notebook here, you can change\n",
    "    # tqdm_notebook to use it outside a notebook\n",
    "    with tarfile.open(RAW_IMAGES_NAME if use_raw else IMAGES_NAME) as f:\n",
    "        for m in tqdm.tqdm_notebook(f.getmembers()):\n",
    "            # Only process image files from the compressed data\n",
    "            if m.isfile() and m.name.endswith(\".jpg\"):\n",
    "                # Prepare image\n",
    "                img = decode_image_from_raw_bytes(f.extractfile(m).read())\n",
    "\n",
    "                # Crop only faces and resize it\n",
    "                img = img[dy:-dy, dx:-dx]\n",
    "                img = cv2.resize(img, (dimx, dimy))\n",
    "\n",
    "                # Parse person and append it to the collected data\n",
    "                fname = os.path.split(m.name)[-1]\n",
    "                fname_splitted = fname[:-4].replace('_', ' ').split()\n",
    "                person_id = ' '.join(fname_splitted[:-1])\n",
    "                photo_number = int(fname_splitted[-1])\n",
    "                if (person_id, photo_number) in imgs_with_attrs:\n",
    "                    all_photos.append(img)\n",
    "                    photo_ids.append({'person': person_id, 'imagenum': photo_number})\n",
    "\n",
    "    photo_ids = pd.DataFrame(photo_ids)\n",
    "    all_photos = np.stack(all_photos).astype('uint8')\n",
    "\n",
    "    # Preserve photo_ids order!\n",
    "    all_attrs = photo_ids.merge(df_attrs, on=('person', 'imagenum')).drop([\"person\", \"imagenum\"], axis=1)\n",
    "\n",
    "    return all_photos, all_attrs\n",
    "\n",
    "# Prépare le dataset et le charge dans la variable X\n",
    "X, attr = load_lfw_dataset(use_raw=True, dimx=32, dimy=32)\n",
    "# Normalise les images\n",
    "X = (X.astype(\"float32\")-127.5)/127.5"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "IAM2021 - TP GAN.ipynb",
   "provenance": [
    {
     "file_id": "1NEuWUdI_RE21-HSnM97Gaiu7r0mgOpzS",
     "timestamp": 1575908111833
    },
    {
     "file_id": "1W6yojd2fpYsDP2mnH_pbyFF8DzormXTA",
     "timestamp": 1575458798048
    },
    {
     "file_id": "1MhBkPZTpU52Jf2Y50ZAMG0kO6e4mS3Il",
     "timestamp": 1574780203309
    },
    {
     "file_id": "1nWQYnWfLw5xvcASlIHosaJWbXPhDIEG1",
     "timestamp": 1574515967280
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
